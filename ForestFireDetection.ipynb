{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Fire Detection System - Main Workflow\n",
    "\n",
    "This Jupyter Notebook serves as the main entry point for the Forest Fire Detection System. It orchestrates the entire workflow, from data preprocessing and dataset creation to model training, evaluation, and hyperparameter tuning. Each step can be run independently or sequentially.\n",
    "https://firms.modaps.eosdis.nasa.gov/descriptions/FIRMS_VIIRS_Firehotspots.html\n",
    "\n",
    "acquired time is UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Add 'aad' directory to sys.path for module imports\n",
    "sys.path.insert(0, os.path.abspath(\"aad\"))\n",
    "\n",
    "from aad.common.config import Config\n",
    "from aad.common.reload_all import reload_all\n",
    "import aad.autoencoder.trainer_standard as trainer_standard\n",
    "import aad.autoencoder.utils as utils\n",
    "import aad.autoencoder.evaluator as evaluator\n",
    "#import aad.model_tuning as model_tuning\n",
    "import aad.autoencoder.clustering as clustering\n",
    "from aad.data.utils import create_full_dataloader\n",
    "from aad.common.core_logging import ProcessLogger\n",
    "\n",
    "# Configure logging for better output in the notebook\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Initialize configuration\n",
    "# You can change these paths as needed\n",
    "DATA_DIR = \"data\"\n",
    "OUTPUT_DIR = \"output_7p_sma\"\n",
    "MODEL_DIR = \"models_7p_sma\"\n",
    "\n",
    "# Set environment variables for the Config class to pick up\n",
    "os.environ['DATA_DIR'] = DATA_DIR\n",
    "os.environ['OUTPUT_DIR'] = OUTPUT_DIR\n",
    "os.environ['MODEL_DIR'] = MODEL_DIR\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(f\"Using data directory: {config.paths.DATA_DIR}\")\n",
    "print(f\"Using output directory: {config.paths.OUTPUT_DIR}\")\n",
    "print(f\"Using model directory: {config.paths.MODEL_DIR}\")\n",
    "\n",
    "# Ensure directories exist (Config() constructor already does this, but explicit is fine)\n",
    "os.makedirs(config.paths.DATA_DIR, exist_ok=True)\n",
    "os.makedirs(config.paths.OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(config.paths.MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Autoencoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section trains the autoencoder neural network using the prepared dataset. The model learns to reconstruct normal environmental patterns, which is crucial for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ForestFireDetection.ipynb\n",
    "\n",
    "import logging\n",
    "from aad.autoencoder.trainer_standard import StandardTrainer\n",
    "from aad.autoencoder.model_vae import VariationalAutoencoder\n",
    "from aad.data.utils import create_dataloaders\n",
    "from aad.common.reload_all import reload_all  # Explicit import for clarity\n",
    "\n",
    "num_features = len(config.data_pipeline.INPUT_COLUMNS) + len(config.data_pipeline.INPUT_COLUMNS) * len(config.data_pipeline.SMA_MULTIPLIERS) * 3 # 3 is sma, min and max\n",
    "config.training.BATCH_SIZE = 256\n",
    "config.tuning.LATENT_DIM = 12\n",
    "\n",
    "\n",
    "model = VariationalAutoencoder(\n",
    "    time_steps=config.data_pipeline.WINDOW_SIZE,\n",
    "    num_features=num_features,\n",
    "    latent_dim=config.tuning.LATENT_DIM,\n",
    "    dropout=0.2,\n",
    "    d_model=num_features,\n",
    "    num_heads=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_all()\n",
    "\n",
    "config.training.RANDOM_SEED = 42\n",
    "config.training.EPOCHS = 10\n",
    "config.training.LEARNING_RATE = 1e-5\n",
    "config.training.PATIENCE = 25\n",
    "config.training.USE_BETA_SCHEDULE = True\n",
    "config.training.BETA_SCHEDULE_TYPE = \"cosine\"\n",
    "config.training.DEVICE = \"cpu\"\n",
    "config.data_pipeline.NUM_SAMPLES = 100_000\n",
    "\n",
    "logger = ProcessLogger(config, \"trainer\")\n",
    "trainer = StandardTrainer(\n",
    "    logger=logger,\n",
    "    random_seed=config.training.RANDOM_SEED,\n",
    "    epochs=config.training.EPOCHS,\n",
    "    patience=config.training.PATIENCE,\n",
    "    learning_rate=config.training.LEARNING_RATE,\n",
    "    loss_function_name=config.training.LOSS_FUNCTION,\n",
    "    optimizer_name=config.training.OPTIMIZER,\n",
    "    batch_size=config.training.BATCH_SIZE,\n",
    "    latent_dim=config.tuning.LATENT_DIM,\n",
    "    hidden_dim=config.tuning.HIDDEN_DIM,\n",
    "    window_size=config.data_pipeline.WINDOW_SIZE,\n",
    "    num_features=len(config.data_pipeline.INPUT_COLUMNS),\n",
    "    device=config.training.DEVICE,\n",
    "    stats_images_dir=config.paths.STATS_IMAGES_DIR,\n",
    "    training_statistics_image_path=config.paths.TRAINING_STATISTICS_IMAGE_PATH,\n",
    "    best_model_path=config.paths.BEST_MODEL_PATH,\n",
    "    loss_history_path=config.paths.LOSS_HISTORY_PATH,\n",
    "    callbacks=None,\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    config.paths.DATASET_PATH,\n",
    "    config.data_pipeline.NUM_SAMPLES,\n",
    "    config.training.RANDOM_SEED,\n",
    "    config.training.TRAIN_SPLIT,\n",
    "    config.training.VAL_SPLIT,\n",
    "    config.training.BATCH_SIZE,\n",
    "    ProcessLogger(config, \"dataloader\"),\n",
    "    remove_fire_labels=True,\n",
    "    fire_threshold_distance_min=20000,\n",
    ")\n",
    "\n",
    "print(train_loader.dataset.tensors[0].shape)\n",
    "model, _ = trainer.train(model, train_loader, val_loader, True)\n",
    "logging.info(\"Training completed successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the model is evaluated to assess its performance in detecting anomalies. This step calculates reconstruction errors, applies anomaly thresholds, and compares predictions against ground truth fire events to compute metrics like precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aad.autoencoder.evaluator import ModelEvaluator\n",
    "import torch\n",
    "\n",
    "test_loader = create_full_dataloader(\n",
    "    config.paths.DATASET_PATH,\n",
    "    None,\n",
    "    config.training.RANDOM_SEED,\n",
    "    config.training.BATCH_SIZE,\n",
    "    ProcessLogger(config, \"dataloader\"),\n",
    ")\n",
    "\n",
    "logger = ProcessLogger(config, \"evaluator\")\n",
    "model.load_state_dict(torch.load(config.paths.BEST_MODEL_PATH, config.training.DEVICE))\n",
    "config.training.ANOMALY_THRESHOLD_PERCENTILE = 99.98\n",
    "config.training.DISTANCE_FILTER_THRESHOLD_M = 7200\n",
    "evaluator = ModelEvaluator(\n",
    "    anomaly_threshold_percentile=config.training.ANOMALY_THRESHOLD_PERCENTILE,\n",
    "    distance_filter_threshold_m=config.training.DISTANCE_FILTER_THRESHOLD_M,\n",
    "    device=config.training.DEVICE,\n",
    "    logger=logger,\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    stats_images_dir=config.paths.STATS_IMAGES_DIR,\n",
    "    stats_csv_dir=config.paths.STATS_CSV_DIR,\n",
    "    eval_stats_img_path=config.paths.EVALUATION_STATISTICS_IMAGE_PATH,\n",
    "    eval_results_csv_path=config.paths.EVALUATION_RESULTS_CSV_PATH,\n",
    "    eval_summary_json_path=config.paths.EVALUATION_SUMMARY_JSON_PATH,\n",
    ")\n",
    "evaluator.evaluate_model(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_CLUSTERING = False\n",
    "\n",
    "if not SKIP_CLUSTERING:\n",
    "    logging.info(\"--- Performing model clustering for the autoencoder model ---\")\n",
    "    reload_all()\n",
    "    dataloader = create_full_dataloader(config)\n",
    "    config.tuning.KMEANS_N_CLUSTERS = 32\n",
    "    config.tuning.DBSCAN_EPS = 0.5\n",
    "    config.tuning.DBSCAN_MIN_SAMPLES = 5\n",
    "    clustering.analyze_embeddings(config, dataloader)\n",
    "else:\n",
    "    logging.info(\"Skipping model clustering for the autoencoder model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This optional step performs hyperparameter tuning to optimize the autoencoder's performance. It systematically explores different combinations of latent dimensions, hidden layers, and anomaly thresholds to find the best configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to skip this step\n",
    "SKIP_HYPERPARAMETER_TUNING = True\n",
    "\n",
    "if not SKIP_HYPERPARAMETER_TUNING:\n",
    "    logging.info(\"--- Performing hyperparameter tuning for the autoencoder model ---\")\n",
    "    #tune_hyperparameters_advanced(config)\n",
    "else:\n",
    "    logging.info(\"Skipping Performing hyperparameter tuning for the autoencoder model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Completed\n",
    "\n",
    "The entire forest fire detection workflow has been executed. You can now review the generated outputs in the `output/` directory.\n",
    "\n",
    "### Key Benefits of the Refactored Structure:\n",
    "- **Clear Module Organization**: Each import now comes from a logically named module\n",
    "- **Single Responsibility**: Each module has a focused purpose\n",
    "- **Easy Maintenance**: Code is organized and easy to find\n",
    "- **No Circular Dependencies**: Clean import structure\n",
    "\n",
    "### Updated Module Mapping:\n",
    "- `data_preprocessing` → Data resampling and windowing\n",
    "- `data_filtering` → Window and distance filtering  \n",
    "- `data_annotation` → Fire distance calculations\n",
    "- `data_sequences` → Dataset creation and sequences\n",
    "- `model_training` → Autoencoder training workflow\n",
    "- `eval_metrics` → Model evaluation and metrics\n",
    "- `eval_tuning` → Hyperparameter optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
