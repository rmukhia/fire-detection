{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fdc8b-e8a6-4dbc-9847-b761aff68a38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T14:31:32.823998Z",
     "iopub.status.busy": "2025-08-28T14:31:32.823622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\conda\\npu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Creating partitions: 100%|██████████| 9/9 [00:00<00:00, 10.29it/s]\n",
      "f:\\conda\\npu\\Lib\\site-packages\\distributed\\client.py:3371: UserWarning: Sending large graph of size 88.77 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2025-08-28 23:19:20,418 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:20,420 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:20,421 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:20,421 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:20,422 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:20,423 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:20,423 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:20,424 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2025-08-28 23:19:21,472 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py\", line 818, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\client.py\", line 1929, in _close\n",
      "    await self.cluster.close()\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\deploy\\spec.py\", line 454, in _close\n",
      "    await self._correct_state()\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\deploy\\spec.py\", line 365, in _correct_state_internal\n",
      "    await asyncio.gather(*tasks)\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\nanny.py\", line 619, in close\n",
      "    await self.kill(timeout=timeout, reason=reason)\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\nanny.py\", line 400, in kill\n",
      "    await self.process.kill(reason=reason, timeout=timeout)\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\nanny.py\", line 883, in kill\n",
      "    await process.join(max(0, deadline - time()))\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\process.py\", line 330, in join\n",
      "    await wait_for(asyncio.shield(self._exit_future), timeout)\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py\", line 1922, in wait_for\n",
      "    async with asyncio.timeout(timeout):\n",
      "  File \"f:\\conda\\npu\\Lib\\asyncio\\timeouts.py\", line 115, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "2025-08-28 23:19:21,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x0000026DE9AF3790>>, <Task finished name='Task-10065' coro=<SpecCluster._correct_state_internal() done, defined at f:\\conda\\npu\\Lib\\site-packages\\distributed\\deploy\\spec.py:352> exception=TimeoutError()>)\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"f:\\conda\\npu\\Lib\\site-packages\\tornado\\ioloop.py\", line 782, in _discard_future_result\n",
      "    future.result()\n",
      "TimeoutError\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py:1923\u001b[0m, in \u001b[0;36mwait_for\u001b[1;34m(fut, timeout)\u001b[0m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[1;32m-> 1923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m     sequencer\u001b[38;5;241m.\u001b[39mcreate_dataset(fit_scaler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemporary_directory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtmp\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Start Dask cluster for the entire pipeline\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads_per_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Preprocessing\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDataPreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_sensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_sensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\client.py:1721\u001b[0m, in \u001b[0;36mClient.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1716\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is deprecated to enter and exit the Client context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1717\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanager from different threads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1718\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1719\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1720\u001b[0m         )\n\u001b[1;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\client.py:1982\u001b[0m, in \u001b[0;36mClient.close\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1979\u001b[0m         coro \u001b[38;5;241m=\u001b[39m wait_for(coro, timeout)\n\u001b[0;32m   1980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m coro\n\u001b[1;32m-> 1982\u001b[0m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_close\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1983\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_finalizing():\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py:452\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m         wait(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py:426\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m    424\u001b[0m         awaitable \u001b[38;5;241m=\u001b[39m wait_for(awaitable, timeout)\n\u001b[0;32m    425\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(awaitable)\n\u001b[1;32m--> 426\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    428\u001b[0m     error \u001b[38;5;241m=\u001b[39m exception\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\tornado\\gen.py:783\u001b[0m, in \u001b[0;36mRunner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 783\u001b[0m         value \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[0;32m    787\u001b[0m         \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n\u001b[0;32m    788\u001b[0m         exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py:1923\u001b[0m, in \u001b[0;36mwait_for\u001b[1;34m(fut, timeout)\u001b[0m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait_for\u001b[39m(fut: Awaitable[T], timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   1922\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[1;32m-> 1923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py:818\u001b[0m, in \u001b[0;36m_LogErrors.__call__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 818\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\client.py:1929\u001b[0m, in \u001b[0;36mClient._close\u001b[1;34m(self, fast)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1928\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m-> 1929\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpc\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\deploy\\spec.py:454\u001b[0m, in \u001b[0;36mSpecCluster._close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isawaitable(f):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m f\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correct_state()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_futures)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_comm:\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\deploy\\spec.py:365\u001b[0m, in \u001b[0;36mSpecCluster._correct_state_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_comm\u001b[38;5;241m.\u001b[39mretire_workers(workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(to_close))\n\u001b[0;32m    360\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    361\u001b[0m         asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers[w]\u001b[38;5;241m.\u001b[39mclose())\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m to_close\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[0;32m    364\u001b[0m     ]\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m to_close:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers:\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\nanny.py:619\u001b[0m, in \u001b[0;36mNanny.close\u001b[1;34m(self, timeout, reason)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(timeout\u001b[38;5;241m=\u001b[39mtimeout, reason\u001b[38;5;241m=\u001b[39mreason)\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpc\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\nanny.py:400\u001b[0m, in \u001b[0;36mNanny.kill\u001b[1;34m(self, timeout, reason)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Kill the local worker process\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03mBlocks until both the process is down and the scheduler is properly\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03minformed\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mkill(reason\u001b[38;5;241m=\u001b[39mreason, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\nanny.py:883\u001b[0m, in \u001b[0;36mWorkerProcess.kill\u001b[1;34m(self, timeout, executor_wait, reason)\u001b[0m\n\u001b[0;32m    879\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    880\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorker process still alive after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwait_timeout\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds, killing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m     )\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m process\u001b[38;5;241m.\u001b[39mkill()\n\u001b[1;32m--> 883\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m process\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, deadline \u001b[38;5;241m-\u001b[39m time()))\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid operation on closed AsyncProcess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\process.py:330\u001b[0m, in \u001b[0;36mAsyncProcess.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Shield otherwise the timeout cancels the future and our\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# on_exit callback will try to set a result on a canceled future\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m wait_for(asyncio\u001b[38;5;241m.\u001b[39mshield(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exit_future), timeout)\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\site-packages\\distributed\\utils.py:1922\u001b[0m, in \u001b[0;36mwait_for\u001b[1;34m(fut, timeout)\u001b[0m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait_for\u001b[39m(fut: Awaitable[T], timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m-> 1922\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[0;32m   1923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "File \u001b[1;32mf:\\conda\\npu\\Lib\\asyncio\\timeouts.py:115\u001b[0m, in \u001b[0;36mTimeout.__aexit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m _State\u001b[38;5;241m.\u001b[39mEXPIRED\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39muncancel() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cancelling \u001b[38;5;129;01mand\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;66;03m# Since there are no new cancel requests, we're\u001b[39;00m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;66;03m# handling this.\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc_val\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01mis\u001b[39;00m _State\u001b[38;5;241m.\u001b[39mENTERED:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m _State\u001b[38;5;241m.\u001b[39mEXITED\n",
      "\u001b[1;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import multiprocessing as mp\n",
    "import dask.config\n",
    "from aad.common.config import Config\n",
    "from aad.data.loader import DataLoader\n",
    "from aad.data.preprocessing import DataPreprocessor\n",
    "from aad.data.annotation import DataAnnotator\n",
    "from aad.data.sequences import DataSequencer\n",
    "from aad.data.groundtruth import GroundTruthCollector\n",
    "from aad.common.core_logging import ProcessLogger\n",
    "\n",
    "from dask.distributed import Client\n",
    "def main():\n",
    "    config = Config()\n",
    "    logger = ProcessLogger(config, 'logger')\n",
    "    loader = DataLoader(config)\n",
    "    # Load all data\n",
    "    df_sensor, _, df_locations = loader.load_raw_data(label_load=False, location_load=True)\n",
    "    n_workers: int = min(mp.cpu_count(), config.data_pipeline.NUM_WORKERS)\n",
    "    dask.config.set({'temporary_directory': r'D:\\tmp'})\n",
    "    # Start Dask cluster for the entire pipeline\n",
    "\n",
    "    with Client(n_workers=4, threads_per_worker=1) as client:\n",
    "        minutes = [16, 30]\n",
    "        for i in minutes:\n",
    "            OUTPUT_DIR = f'D:/ff_data/output_{i}min_7h'\n",
    "            MODEL_DIR = f'model_{i}min_7h'\n",
    "            DATASET_DIR = f'dataset_{i}min_7h'\n",
    "\n",
    "            # Set environment variables for the Config class to pick up\n",
    "            os.environ['OUTPUT_DIR'] = OUTPUT_DIR\n",
    "            os.environ['MODEL_DIR'] = MODEL_DIR\n",
    "            os.environ['DATASET_DIR'] = DATASET_DIR\n",
    "\n",
    "            config = Config()\n",
    "            config.data_pipeline.LOCAL_OFFSET_MINUTES = 420\n",
    "            config.data_pipeline.WINDOW_DURATION_MINUTES = i\n",
    "\n",
    "            print(f'Processing with window size {i} minutes and offset 7h')\n",
    "            \n",
    "            # Preprocessing\n",
    "            preprocessor = DataPreprocessor(config, df_sensor=df_sensor, logger=logger)\n",
    "            preprocessor.preprocess_data(client=client)\n",
    "            # Ground Truth Processing\n",
    "            groundtruth_collector = GroundTruthCollector(config)\n",
    "            df_groundtruth = groundtruth_collector.collect_groundtruth(start_end_offset_min=180)\n",
    "            # Annotation (using ground truth as labels)\n",
    "            annotator = DataAnnotator(config, df_labels=df_groundtruth, df_locations=df_locations, logger=logger)\n",
    "            annotator.annotate_data(client=client)\n",
    "            # Sequence creation\n",
    "            sequencer = DataSequencer(config, logger=logger)\n",
    "            sequencer.create_dataset(fit_scaler=True)\n",
    "            %%\n",
    "\n",
    "        for i in minutes:       \n",
    "            OUTPUT_DIR = f'D:/ff_data/output_{i}min_0h'\n",
    "            MODEL_DIR = f'model_{i}min_0h'\n",
    "            DATASET_DIR = f'dataset_{i}min_0h'\n",
    "\n",
    "            # Set environment variables for the Config class to pick up\n",
    "            os.environ['OUTPUT_DIR'] = OUTPUT_DIR\n",
    "            os.environ['MODEL_DIR'] = MODEL_DIR\n",
    "            os.environ['DATASET_DIR'] = DATASET_DIR\n",
    "\n",
    "            config = Config()\n",
    "            config.data_pipeline.WINDOW_DURATION_MINUTES = i\n",
    "            config.data_pipeline.LOCAL_OFFSET_MINUTES = 0\n",
    "\n",
    "            print(f'Processing with window size {i} minutes and offset 0h')\n",
    "            \n",
    "            # Preprocessing\n",
    "            preprocessor = DataPreprocessor(config, df_sensor=df_sensor, logger=logger)\n",
    "            preprocessor.preprocess_data(client=client)\n",
    "            # Ground Truth Processing\n",
    "            groundtruth_collector = GroundTruthCollector(config)\n",
    "            df_groundtruth = groundtruth_collector.collect_groundtruth(start_end_offset_min=180)\n",
    "            # Annotation (using ground truth as labels)\n",
    "            annotator = DataAnnotator(config, df_labels=df_groundtruth, df_locations=df_locations, logger=logger)\n",
    "            annotator.annotate_data(client=client)\n",
    "            # Sequence creation\n",
    "            sequencer = DataSequencer(config, logger=logger)\n",
    "            sequencer.create_dataset(fit_scaler=True)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
